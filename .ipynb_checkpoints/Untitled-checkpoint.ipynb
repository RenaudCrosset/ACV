{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3ddbdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cd5a28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d941d9c",
   "metadata": {},
   "source": [
    "# Essai 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2045ee00",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94f44315",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PyQt5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m animation\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mPyQt5\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Video\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'PyQt5'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "import PyQt5\n",
    "from PIL import Image\n",
    "from IPython.display import Video\n",
    "import nb_helpers\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_face_mesh = mp.solutions.face_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe503188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6484f98e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e87b74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10ccd6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9d2b282",
   "metadata": {},
   "source": [
    "# Essai 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f043cc5c",
   "metadata": {},
   "source": [
    "https://www.geeksforgeeks.org/face-and-hand-landmarks-detection-using-python-mediapipe-opencv/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d896eb3e",
   "metadata": {},
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20f91360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8009b939",
   "metadata": {},
   "source": [
    "Initializing Holistic model and Drawing utils for detecting and drawing landmarks on the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f857e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing the Holistic Model from Mediapipe and\n",
    "# Initializing the Model\n",
    "mp_holistic = mp.solutions.holistic\n",
    "holistic_model = mp_holistic.Holistic(\n",
    "    static_image_mode=False,         # static images or video stream\n",
    "    model_complexity=1,              # 0, 1, or 2 : it increases landmark accuracy and latency. \n",
    "    smooth_landmarks=True,           # reduce the jitter in the prediction by filtering pose landmarks across different input images\n",
    "    min_detection_confidence=0.5,    # minimum confidence value with which the detection from the person-detection model needs to be considered as successful. Can specify a value in [0.0,1.0]\n",
    "    min_tracking_confidence=0.5)     # minimum confidence value with which the detection from the landmark-tracking model must be considered as successful. Can specify a value in [0.0,1.0]\n",
    "\n",
    "# Initializing the drawng utils for drawing the facial landmarks on image\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdec7f6",
   "metadata": {},
   "source": [
    "STEP-3: Detecting Face and Hand landmarks from the image. Holistic model processes the image and produces landmarks for Face, Left Hand, Right Hand and also detects the Pose of the \n",
    "\n",
    "- Capture the frames continuously from the camera using OpenCV.\n",
    "- Convert the BGR image to an RGB image and make predictions using initialized holistic model.\n",
    "- The predictions made by the holistic model are saved in the results variable from which we can access the landmarks using results.face_landmarks, results.right_hand_landmarks, results.left_hand_landmarks respectively.\n",
    "- Draw the detected landmarks on the image using the draw_landmarks function from drawing utils.\n",
    "- Display the resulting Image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4262096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (0) in VideoCapture is used to connect to your computer's default camera\n",
    "capture = cv2.VideoCapture(0)\n",
    " \n",
    "# Initializing current time and precious time for calculating the FPS\n",
    "previousTime = 0\n",
    "currentTime = 0\n",
    " \n",
    "while capture.isOpened():\n",
    "    # capture frame by frame\n",
    "    ret, frame = capture.read()\n",
    " \n",
    "    # resizing the frame for better view\n",
    "    frame = cv2.resize(frame, (800, 600))\n",
    " \n",
    "    # Converting the from BGR to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    " \n",
    "    # Making predictions using holistic model\n",
    "    # To improve performance, optionally mark the image as not writable to\n",
    "    # pass by reference.\n",
    "    image.flags.writable = False\n",
    "    results = holistic_model.process(image)\n",
    "    image.flags.writable = True\n",
    " \n",
    "    # Converting back the RGB image to BGR\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    " \n",
    "    # Drawing the Facial Landmarks\n",
    "    mp_drawing.draw_landmarks(\n",
    "      image,\n",
    "      results.face_landmarks,\n",
    "      mp_holistic.FACE_CONNECTIONS,\n",
    "      mp_drawing.DrawingSpec(\n",
    "        color=(255,0,255),\n",
    "        thickness=1,\n",
    "        circle_radius=1\n",
    "      ),\n",
    "      mp_drawing.DrawingSpec(\n",
    "        color=(0,255,255),\n",
    "        thickness=1,\n",
    "        circle_radius=1\n",
    "      )\n",
    "    )\n",
    " \n",
    "    # Drawing Right hand Land Marks\n",
    "    mp_drawing.draw_landmarks(\n",
    "      image,\n",
    "      results.right_hand_landmarks,\n",
    "      mp_holistic.HAND_CONNECTIONS\n",
    "    )\n",
    " \n",
    "    # Drawing Left hand Land Marks\n",
    "    mp_drawing.draw_landmarks(\n",
    "      image,\n",
    "      results.left_hand_landmarks,\n",
    "      mp_holistic.HAND_CONNECTIONS\n",
    "    )\n",
    "     \n",
    "    # Calculating the FPS\n",
    "    currentTime = time.time()\n",
    "    fps = 1 / (currentTime-previousTime)\n",
    "    previousTime = currentTime\n",
    "     \n",
    "    # Displaying FPS on the image\n",
    "    cv2.putText(image, str(int(fps))+\" FPS\", (10, 70), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    " \n",
    "    # Display the resulting image\n",
    "    cv2.imshow(\"Facial and Hand Landmarks\", image)\n",
    " \n",
    "    # Enter key 'q' to break the loop\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "# When all the process is done\n",
    "# Release the capture and destroy all windows\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf26427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to access landmarks\n",
    "for landmark in mp_holistic.HandLandmark:\n",
    "    print(landmark, landmark.value)\n",
    " \n",
    "print(mp_holistic.HandLandmark.WRIST.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da341373",
   "metadata": {},
   "source": [
    "# Essai 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71263d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ee450c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
